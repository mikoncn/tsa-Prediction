import pandas as pd
from prophet import Prophet
import matplotlib.pyplot as plt

# 1. åŠ è½½æ•°æ® (From DB)
print("Loading data from SQLite (traffic_full)...")
import sqlite3
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
from src.config import DB_PATH

conn = sqlite3.connect(DB_PATH)
df = pd.read_sql("SELECT * FROM traffic_full", conn)
conn.close()

# æ ¼å¼è½¬æ¢
df['ds'] = pd.to_datetime(df['date'])
df['y'] = df['throughput']

# å…³é”®ä¿®å¤: å¿…é¡»æŒ‰æ—¥æœŸå‡åºæ’åˆ—ï¼Œå¦åˆ™ shift è®¡ç®—ä¼šé”™ä¹±
df = df.sort_values('ds').reset_index(drop=True)

# 2. ç‰¹å¾å·¥ç¨‹ (On-the-Fly)
print("Generating Lag Features...")
# Lag 7: å·²ç»åœ¨æ•°æ®åº“é‡Œæœ‰äº†ï¼Œé‡å‘½åä¸€ä¸‹æ–¹ä¾¿å¼•ç”¨ (æˆ–è€…ç›´æ¥ç”¨ throughput_lag_7)
df['lag_7'] = df['throughput_lag_7']

# Lag 364: åŒæ¯”ç‰¹å¾ (Shift 52 weeks = 364 days, aligning day-of-week)
df['lag_364'] = df['y'].shift(364)

# [NEW] Off-Peak Workday Bias Correction (Synced from Backtest V2)
print("Generating bias correction features (Off-Peak Tue/Wed)...")
match_month = df['ds'].dt.month.isin([1, 2, 9, 10])
match_day = df['ds'].dt.dayofweek.isin([1, 2]) # 0=Mon, 1=Tue, 2=Wed
df['is_off_peak_workday'] = (match_month & match_day).astype(int)

# DEBUG: Check tail of raw data
print("\n[DEBUG] Raw Data Tail (Last 5 rows):")
print(df[['ds', 'y', 'lag_364']].tail())

# DEBUG: Check specific target dates
target_check_dates = ['2026-01-16', '2026-01-17', '2026-01-18']
print(f"\n[DEBUG] Checking Target Dates {target_check_dates}:")
print(df[df['ds'].astype(str).isin(target_check_dates)][['ds', 'y', 'lag_364']])

# å¡«å…… Lags çš„ç©ºå€¼ (å¼€å¤´çš„ä¸€å¹´æ•°æ®æ²¡æœ‰ lag_364)
# Prophet ä¸å…è®¸ regressor æœ‰ NaNï¼Œæ‰€ä»¥æˆ‘ä»¬å¿…é¡»ä¸¢å¼ƒå¼€å¤´ï¼Œæˆ–è€…å¡«å……
# æˆ‘ä»¬é€‰æ‹©ä¸¢å¼ƒ lag_364 ä¸ºç©ºçš„è¡Œ (å³ç¬¬ä¸€å¹´æ•°æ®æ— æ³•ç”¨äºè®­ç»ƒ)
df_model = df.dropna(subset=['lag_364']) 

# å¡«è¡¥å…¶ä»–å¯èƒ½çš„ç©ºå€¼
features = ['weather_index', 'is_holiday', 'is_spring_break', 'lag_7', 'lag_364', 'is_off_peak_workday']
for col in features:
    df_model[col] = df_model[col].fillna(0) 

print(f"Data ready. Total rows: {len(df_model)}")
print(f"Model Date Range: {df_model['ds'].min()} to {df_model['ds'].max()}")

# 3. åˆå§‹åŒ–æ¨¡å‹ (The Engine)
print("Initializing Prophet Model...")
m = Prophet(
    daily_seasonality=False,
    yearly_seasonality=True,
    weekly_seasonality=True,
    seasonality_mode='multiplicative',
    changepoint_prior_scale=0.15 # Tuned for fast trend adaptation
)

# 4. æ³¨å…¥æ ¸æ­¦å™¨ (Regressors)
print("Adding Regressors...")
m.add_regressor('weather_index')
m.add_regressor('is_holiday')
m.add_regressor('is_spring_break')
m.add_regressor('lag_7')
m.add_regressor('lag_364')
m.add_regressor('is_off_peak_workday') # [NEW]

# 5. è®­ç»ƒ (Fit)
# è®­ç»ƒé›†: y ä¸ä¸ºç©ºçš„è¡Œ
train_df = df_model[df_model['y'].notnull()]

# [NEW] å…³é”®æ¸…æ´—: å‰”é™¤ 2020-2021 ç–«æƒ…ä¸¥é‡æœŸé—´çš„æ•°æ®
# è¿™æ®µæ—¶é—´çš„å®¢æµæ˜¯æå…¶å¼‚å¸¸çš„ (ä¸‹é™95%)ï¼Œå¦‚æœä¸å‰”é™¤ï¼Œä¼šä¸¥é‡è¯¯å¯¼æ¨¡å‹çš„"å‘¨æœŸæ€§"åˆ¤æ–­
# æˆ‘ä»¬ä¿ç•™ 2019 (æ­£å¸¸) å’Œ 2022ä»¥å (æ¢å¤å)
pandemic_start = '2020-03-01'
pandemic_end = '2021-12-31'
print(f"Filtering out Pandemic Era ({pandemic_start} ~ {pandemic_end})...")

mask_pandemic = (train_df['ds'] >= pandemic_start) & (train_df['ds'] <= pandemic_end)
train_df = train_df[~mask_pandemic]

print(f"Fitting model on {len(train_df)} rows (Clean Normal Data)...")
m.fit(train_df)

# 6. é¢„æµ‹ (Predict)
# é¢„æµ‹é›†: åŒ…å«æœªæ¥çš„è¡Œ
print("Predicting...")
forecast = m.predict(df_model)

# 7. è¾“å‡ºæˆ˜æŠ¥ (The Alpha)
target_dates = ['2026-01-14', '2026-01-15', '2026-01-16', '2026-01-17', '2026-01-18']
report_lines = []
report_lines.append("\n" + "="*50)
report_lines.append("ğŸš€ FUTURE FORECAST REPORT")
report_lines.append("="*50)

subset = forecast[forecast['ds'].astype(str).isin(target_dates)]

if len(subset) == 0:
    report_lines.append("âŒ Critical Error: No forecast generated for target dates!")
else:
    for _, row in subset.iterrows():
        d_str = row['ds'].strftime('%Y-%m-%d')
        yhat = int(row['yhat'])
        lower = int(row['yhat_lower'])
        upper = int(row['yhat_upper'])
        reg_effect = row['extra_regressors_multiplicative']
        
        report_lines.append(f"ğŸ“… {d_str} | ğŸ”® é¢„æµ‹: {yhat:,} äººæ¬¡")
        report_lines.append(f"   èŒƒå›´: [{lower:,} ~ {upper:,}]")
        report_lines.append(f"   å› å­åŠ æˆ: {reg_effect:.4f} (åŸºå‡†=0, >0ä¸ºæ­£å‘æ‹‰åŠ¨)")
        report_lines.append("-" * 30)

    # 8. ç‰¹æ®Šæ£€æŸ¥: 1æœˆ16æ—¥ (æ˜å¤©) çš„è¯¦ç»†æ„æˆ
    report_lines.append("\nğŸ” DEEP DIVE: 2026-01-16 (Tomorrow)")
    report_lines.append("="*50)
    target_row = forecast[forecast['ds'].astype(str) == '2026-01-16']
    
    if len(target_row) > 0:
        target_day = target_row.iloc[0]
        trend = target_day['trend']
        weekly = target_day['weekly']
        yearly = target_day['yearly']
        
        report_lines.append(f"åŸºç¡€è¶‹åŠ¿ (Trend): {int(trend):,}")
        report_lines.append(f"å‘¨æœŸæ€§ (Seasonality):")
        report_lines.append(f"  - Weekly: {weekly:.4f}")
        report_lines.append(f"  - Yearly: {yearly:.4f}")
        
        report_lines.append(f"å¤–éƒ¨å›å½’ (Regressors):")
        if 'weather_index' in target_day:
            report_lines.append(f"  - Weather Index Effect: {target_day['weather_index']:.4f}")
        if 'is_holiday' in target_day:
            report_lines.append(f"  - Holiday Effect: {target_day['is_holiday']:.4f}")
        if 'lag_7' in target_day:
            report_lines.append(f"  - Lag-7 Effect: {target_day['lag_7']:.4f}")
        if 'lag_364' in target_day:
            report_lines.append(f"  - Lag-364 Effect: {target_day['lag_364']:.4f}")

        report_lines.append(f"\nFinal yhat = Trend * (1 + Weekly + Yearly + Regressors)")
        report_lines.append("="*50)

# Write to file
with open("model_report.txt", "w", encoding="utf-8") as f:
    f.write("\n".join(report_lines))

print("Report saved to model_report.txt")
