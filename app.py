from flask import Flask, render_template, jsonify
import sqlite3
import pandas as pd
import os

app = Flask(__name__)

# [NEW] Import config
import sys
# Ensure src can be imported if app.py is run directly
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
from src.config import DB_PATH

# è·å–æ•°æ®åº“è¿æ¥çš„åŠ©æ‰‹å‡½æ•°
def get_db_connection():
    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row  # å…è®¸é€šè¿‡åˆ—åè®¿é—®ç»“æœ
    return conn

# ä¸»é¡µè·¯ç”±ï¼šè¿”å›ä»ªè¡¨ç›˜ HTML
@app.route('/')
def index():
    return render_template('index.html')

# API: è·å–å†å²æµé‡æ•°æ® (ç”¨äºç»˜åˆ¶ä¸»å›¾è¡¨)
@app.route('/api/data')
def get_data():
    conn = get_db_connection()
    # æŸ¥è¯¢å…¨é‡å®½è¡¨ (åŒ…å«å¤©æ°”å’ŒèŠ‚æ—¥ç‰¹å¾)
    # é™åˆ¶ä¸ºå½“å‰æ—¶é—´ä¹‹å‰çš„æ•°æ®ï¼Œæˆ–è€…å…¨éƒ¨æ•°æ®
    query = """
        SELECT date, throughput, weather_index, is_holiday, holiday_name 
        FROM traffic_full 
        WHERE date <= date('now') 
        ORDER BY date ASC
    """
    try:
        rows = conn.execute(query).fetchall()
    except sqlite3.OperationalError:
        # Fallback if traffic_full doesn't exist yet
        rows = conn.execute('SELECT date, throughput FROM traffic ORDER BY date ASC').fetchall()
        
    conn.close()
    
    data = []
    for row in rows:
        item = {
            'date': row['date'],
            'throughput': row['throughput']
        }
        # Add features if they exist
        if 'weather_index' in row.keys():
            item['weather_index'] = row['weather_index']
            item['is_holiday'] = row['is_holiday']
            item['holiday_name'] = row['holiday_name']
        
        data.append(item)
        
    return jsonify(data)
# API: è·å–é¢„æµ‹ç»“æœå’Œå†å²éªŒè¯æ•°æ®
@app.route('/api/predictions')
def get_predictions():
    result = {}
    
    try:
        conn = sqlite3.connect('tsa_data.db')
        conn.row_factory = sqlite3.Row
        
        from datetime import datetime
        now_str = datetime.now().strftime('%Y-%m-%d')
        
        # 1. åŠ è½½æœªæ¥é¢„æµ‹ (Forecast) - From SQLite 'prediction_history'
        # Logic: Get predictions for Date >= Today
        query_forecast = """
            SELECT target_date, predicted_throughput, model_run_date 
            FROM prediction_history 
            WHERE target_date >= ?
        """
        df_preds = pd.read_sql(query_forecast, conn, params=(now_str,))
        
        if not df_preds.empty:
            # Dedupe: keep latest model_run_date for each target_date
            df_preds['target_date'] = pd.to_datetime(df_preds['target_date']).dt.strftime('%Y-%m-%d')
            # Sort by run_date DESC, keep first
            df_forecast = df_preds.sort_values('model_run_date', ascending=False).drop_duplicates('target_date')
            # Sort by date ASC for chart
            df_forecast = df_forecast.sort_values('target_date')
            
            result['forecast'] = df_forecast[['target_date', 'predicted_throughput']].rename(columns={
                'target_date': 'ds',
                'predicted_throughput': 'predicted_throughput'
            }).to_dict(orient='records')
        else:
            result['forecast'] = []

        # 2. åŠ è½½å†å²éªŒè¯ (Validation) - From SQLite 'prediction_history' & 'traffic_full'
        # Query History (Past predictions)
        query_hist = "SELECT target_date, predicted_throughput, model_run_date FROM prediction_history WHERE target_date < ?"
        df_hist = pd.read_sql(query_hist, conn, params=(now_str,))
        
        # [FIX] Generate 'History' (Orange Line) separately from Validation
        # History should show ALL past predictions, even if we don't have actuals yet.
        if not df_hist.empty:
            # 1. Standardize formatting
            df_hist['target_date'] = pd.to_datetime(df_hist['target_date']).dt.strftime('%Y-%m-%d')
            # 2. Keep latest prediction per date
            df_hist_clean = df_hist.sort_values('model_run_date', ascending=False).drop_duplicates('target_date')
            # 3. Sort for chart
            df_hist_clean = df_hist_clean.sort_values('target_date')
            
            result['history'] = df_hist_clean[['target_date', 'predicted_throughput']].rename(columns={
                'target_date': 'date',
                'predicted_throughput': 'predicted'
            }).to_dict(orient='records')
        else:
            result['history'] = []
            
        # Query Actuals (From traffic_full)
        query_actual = "SELECT date, throughput FROM traffic_full WHERE throughput IS NOT NULL"
        df_actual = pd.read_sql(query_actual, conn)
        
        conn.close()
        
        # Validation Table (Only where we have BOTH Prediction AND Actuals)
        if not df_hist.empty and not df_actual.empty:
            # Standardization
            # df_hist['target_date'] is already standardized above
            df_actual['date'] = pd.to_datetime(df_actual['date']).dt.strftime('%Y-%m-%d')
            
            # Merge
            merged = pd.merge(df_hist, df_actual, left_on='target_date', right_on='date', how='inner')
            
            # Keep latest prediction per target date (using target_date for dedupe logic works, or date)
            merged = merged.sort_values('model_run_date', ascending=False).drop_duplicates('target_date')
            
            # Calculate Error
            merged['difference'] = merged['predicted_throughput'] - merged['throughput']
            merged['error_rate'] = (merged['difference'].abs() / merged['throughput']) * 100
            
            # Formatting
            # We already have 'date' from df_actual. We don't need to rename target_date to date.
            # But we might need to ensure target_date is dropped or just ignored.
            merged = merged.rename(columns={
                'throughput': 'actual',
                'predicted_throughput': 'predicted'
            })
            
            # Select columns explicitly
            merged = merged[['date', 'actual', 'predicted', 'difference', 'error_rate']]
            
            merged = merged.sort_values('date', ascending=True)
            merged = merged.fillna(0)
            
            result['validation'] = merged[['date', 'actual', 'predicted', 'difference', 'error_rate']].to_dict(orient='records')
        else:
            result['validation'] = []
            
    except Exception as e:
        print(f"Error in get_predictions (DB Mode): {e}")
        import traceback
        traceback.print_exc()
        result['forecast'] = []
        result['validation'] = []
        result['history'] = []
        
    return jsonify(result)

# API: ç‚¹å‡»é¡µé¢æŒ‰é’®æ—¶æ‰‹åŠ¨è§¦å‘æ¨¡å‹é‡æ–°è®­ç»ƒå’Œé¢„æµ‹
@app.route('/api/run_prediction', methods=['POST'])
def run_prediction():
    try:
        import subprocess
        import sys
        print("ğŸš€ æ­£åœ¨è§¦å‘æ¨¡å‹è¿è¡Œ (train_xgb.py)...")
        print(f"   Python executable: {sys.executable}")
        print(f"   Working directory: {os.getcwd()}")
        
        # è¿è¡Œå­è¿›ç¨‹æ‰§è¡Œè®­ç»ƒè„šæœ¬
        # æ³¨æ„ï¼šæ­¤å¤„å¤„ç†äº† Windows ç¯å¢ƒä¸‹çš„ GBK ç¼–ç é—®é¢˜
        result = subprocess.run(
            [sys.executable, '-m', 'src.models.train_xgb'], 
            capture_output=True, 
            text=True,
            encoding='utf-8',
            errors='replace',  # è§£ç å¤±è´¥æ—¶æ›¿æ¢å­—ç¬¦è€ŒéæŠ¥é”™
            cwd=os.getcwd(),
            timeout=60  # 60ç§’è¶…æ—¶ä¿æŠ¤
        )
        
        # æ‰“å°å®Œæ•´è¾“å‡ºç”¨äºè°ƒè¯•
        if result.stdout:
            print(f"ğŸ“ STDOUT:\n{result.stdout}")
        if result.stderr:
            print(f"âš ï¸ STDERR:\n{result.stderr}")
        
        if result.returncode == 0:
            print("âœ… Model Run Success")
            # æå–æœ€åå‡ è¡Œè¾“å‡ºä½œä¸ºæ‘˜è¦
            output_lines = result.stdout.strip().split('\n')
            summary = '\n'.join(output_lines[-5:]) if len(output_lines) > 5 else result.stdout
            return jsonify({
                'status': 'success', 
                'message': 'é¢„æµ‹å®Œæˆ!æ•°æ®å·²æ›´æ–°',
                'summary': summary
            })
        else:
            error_msg = result.stderr if result.stderr else result.stdout
            print(f"âŒ Model Run Failed (returncode={result.returncode})")
            return jsonify({
                'status': 'error', 
                'message': f'æ¨¡å‹è¿è¡Œå¤±è´¥: {error_msg}'
            }), 500
            
    except subprocess.TimeoutExpired:
        print(f"âŒ Timeout: æ¨¡å‹è¿è¡Œè¶…è¿‡60ç§’")
        return jsonify({'status': 'error', 'message': 'æ¨¡å‹è¿è¡Œè¶…æ—¶(>60ç§’)'}), 500
    except Exception as e:
        print(f"âŒ Execution Error: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({'status': 'error', 'message': str(e)}), 500

# API: ä¸€é”®æ›´æ–°æ•°æ®(æŠ“å–TSA+å¤©æ°”+åˆå¹¶)
@app.route('/api/update_data', methods=['POST'])
def update_data():
    try:
        import subprocess
        import sys
        print("ğŸ”„ å¼€å§‹æ•°æ®æ›´æ–°æµç¨‹...")
        
        steps = [
            {'name': 'æŠ“å–æœ€æ–°TSAæ•°æ®', 'cmd': [sys.executable, '-m', 'src.etl.build_tsa_db', '--latest'], 'timeout': 30},
            # [NEW] Fetch ONLY recent flight data (Critical for Sniper) with Fail-Fast mode
            {'name': 'åŒæ­¥OpenSkyèˆªç­æ•°æ®(æœ€è¿‘3å¤©)', 'cmd': [sys.executable, '-m', 'src.etl.fetch_opensky', '--recent', '--fail-fast'], 'timeout': 60},
            {'name': 'åŒæ­¥å¤©æ°”ç‰¹å¾', 'cmd': [sys.executable, '-m', 'src.etl.get_weather_features'], 'timeout': 45},
            {'name': 'åˆå¹¶æ•°æ®åº“', 'cmd': [sys.executable, '-m', 'src.etl.merge_db'], 'timeout': 30},
            {'name': 'å…¨é‡æ¨¡å‹é‡è®­(Persistence)', 'cmd': [sys.executable, '-m', 'src.models.train_xgb'], 'timeout': 120}
        ]
        
        results = []
        for step in steps:
            print(f"\n[æ­¥éª¤] {step['name']}...")
            result = subprocess.run(
                step['cmd'], capture_output=True, text=True,
                encoding='utf-8', errors='replace',
                cwd=os.getcwd(), timeout=step['timeout']
            )
            
            if result.returncode == 0:
                print(f"âœ… {step['name']} å®Œæˆ")
                output_lines = result.stdout.strip().split('\n')
                summary = '\n'.join(output_lines[-3:]) if len(output_lines) > 3 else result.stdout
                results.append({'step': step['name'], 'status': 'success', 'summary': summary})
            else:
                error_msg = result.stderr if result.stderr else result.stdout
                print(f"âŒ {step['name']} å¤±è´¥: {error_msg}")
                return jsonify({'status': 'error', 'message': f'{step["name"]}å¤±è´¥', 'error': error_msg}), 500
        
        print("\nâœ… æ•°æ®æ›´æ–°æµç¨‹å…¨éƒ¨å®Œæˆ")
        return jsonify({'status': 'success', 'message': 'æ•°æ®æ›´æ–°æˆåŠŸ!', 'results': results})
        
    except subprocess.TimeoutExpired as e:
        print(f"âŒ è¶…æ—¶: {e}")
        return jsonify({'status': 'error', 'message': f'æ“ä½œè¶…æ—¶: {e}'}), 500
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({'status': 'error', 'message': str(e)}), 500

# API: ç‹™å‡»æ¨¡å‹ (T+0 Nowcasting)
@app.route('/api/predict_sniper', methods=['POST'])
def predict_sniper():
    try:
        import subprocess
        import sys
        import json
        
        # Determine target date? For now default to script default (Today/Tomorrow)
        # Or accept from JSON body if needed
        
        print("ğŸ¯ å¯åŠ¨ç‹™å‡»æ¨¡å‹ (Sniper Mode)...")
        
        # Run script
        result = subprocess.run(
            [sys.executable, '-m', 'src.models.predict_sniper'],
            capture_output=True,
            text=True,
            encoding='utf-8', 
            errors='replace',
            cwd=os.getcwd(),
            timeout=30 # Fast timeout
        )
        
        if result.returncode == 0:
            # Parse JSON from stdout
            try:
                # Script might print other things, find the JSON line
                lines = result.stdout.strip().split('\n')
                # Assume last line is JSON
                json_str = lines[-1]
                data = json.loads(json_str)
                
                # [FIX] Check for internal script error
                if "error" in data:
                     print(f"âŒ Sniper Internal Error: {data['error']}")
                     return jsonify({'status': 'error', 'message': data['error']}), 500
                     
                print(f"âœ… Sniper Hit: {data}")
                return jsonify({'status': 'success', 'data': data})
            except Exception as parse_err:
                print(f"âš ï¸ JSON Parse Error: {parse_err}. Stdout: {result.stdout}")
                return jsonify({'status': 'error', 'message': 'æ— æ³•è§£ææ¨¡å‹è¾“å‡º', 'raw': result.stdout}), 500
        else:
            print(f"âŒ Sniper Missed: {result.stderr}")
            return jsonify({'status': 'error', 'message': 'æ¨¡å‹è¿è¡Œå¤±è´¥', 'error': result.stderr}), 500
            
    except Exception as e:
        print(f"âŒ Sniper Error: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/run_challenger', methods=['POST'])
def run_challenger():
    """è§¦å‘ FLAML æ·±åº¦åˆ†æ (Challenger Model)"""
    try:
        import subprocess
        import sys
        import json
        
        print("ğŸŸ£ å¯åŠ¨ FLAML æŒ‘æˆ˜è€…è®­ç»ƒä»»åŠ¡...")
        
        # è¿è¡Œè®­ç»ƒè„šæœ¬
        result = subprocess.run(
            [sys.executable, '-m', 'src.models.train_challenger'],
            capture_output=True,
            text=True,
            encoding='utf-8',
            errors='replace',
            timeout=600 # 10åˆ†é’Ÿè¶…æ—¶
        )
        
        if result.returncode != 0:
            return jsonify({
                'status': 'error', 
                'message': f"Training failed: {result.stderr}"
            }), 500
            
        # è¯»å–ç”Ÿæˆçš„æ‘˜è¦
        if os.path.exists("challenger_summary.json"):
            with open("challenger_summary.json", 'r') as f:
                summary = json.load(f)
            return jsonify({
                'status': 'success',
                'data': summary
            })
        else:
             return jsonify({
                'status': 'error', 
                'message': "Model trained but no summary file found."
            }), 500
            
    except Exception as e:
        return jsonify({'status': 'error', 'message': str(e)}), 500

if __name__ == '__main__':
    app.run(debug=True, port=5001)
