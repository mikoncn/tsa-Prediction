import pandas as pd
import numpy as np
from xgboost import XGBRegressor
from sklearn.metrics import mean_absolute_percentage_error
import warnings
warnings.filterwarnings('ignore')

# 1. åŠ è½½æ•°æ®
print("Loading data for 2025 Full Scale Backtest...")
df = pd.read_csv("TSA_Final_Analysis.csv")
df['ds'] = pd.to_datetime(df['date'])
df['y'] = df['throughput']
df = df.sort_values('ds').reset_index(drop=True)

# 2. ç‰¹å¾å·¥ç¨‹ (ä¸€è‡´æ€§ä¿æŒ)
print("Generating features...")
df['day_of_week'] = df['ds'].dt.dayofweek
df['month'] = df['ds'].dt.month
df['year'] = df['ds'].dt.year
df['day_of_year'] = df['ds'].dt.dayofyear
df['week_of_year'] = df['ds'].dt.isocalendar().week.astype(int)
df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)

df['lag_7'] = df['throughput_lag_7']
df['lag_364'] = df['y'].shift(364)

# Off-Peak Workday
match_month = df['ds'].dt.month.isin([1, 2, 9, 10])
match_day = df['ds'].dt.dayofweek.isin([1, 2])
df['is_off_peak_workday'] = (match_month & match_day).astype(int)

features = [
    'day_of_week', 'month', 'year', 'day_of_year', 'week_of_year', 'is_weekend',
    'weather_index', 'is_holiday', 'is_spring_break', 'is_off_peak_workday',
    'is_holiday_exact_day', 'is_holiday_travel_window',
    'lag_7', 'lag_364'
]

# 3. ä¸¥æ ¼æ•°æ®åˆ‡åˆ† (Strict Split)
# è®­ç»ƒé›†: æˆªæ­¢åˆ° 2024-12-31 (å®Œå…¨ä¸çœ‹2025)
# å¹¶ä¸”å‰”é™¤ç–«æƒ… (2020-03-01 ~ 2021-12-31)
pandemic_start = pd.Timestamp('2020-03-01')
pandemic_end = pd.Timestamp('2021-12-31')
train_cutoff = pd.Timestamp('2024-12-31') # [CHANGED]

df_model = df.dropna(subset=['lag_364']).copy()
for col in features:
    df_model[col] = df_model[col].fillna(0)

mask_train_period = (df_model['ds'] <= train_cutoff)
mask_pandemic = (df_model['ds'] >= pandemic_start) & (df_model['ds'] <= pandemic_end)

train_df = df_model[mask_train_period & (~mask_pandemic)]

# æµ‹è¯•é›†: 2025 å…¨å¹´ (The Gauntlet)
test_start = pd.Timestamp('2025-01-01')
test_end = pd.Timestamp('2025-12-31')
test_df = df_model[(df_model['ds'] >= test_start) & (df_model['ds'] <= test_end)].copy()

print(f"Training Data: {len(train_df)} rows (End: {train_df['ds'].max().date()})")
print(f"Test Data: {len(test_df)} rows ({test_start.date()} ~ {test_end.date()})")

X_train = train_df[features]
y_train = train_df['y']
X_test = test_df[features]
y_test = test_df['y']

# 4. è®­ç»ƒ XGBoost
print("Training XGBoost Model...")
model = XGBRegressor(
    n_estimators=1000,
    learning_rate=0.05,
    max_depth=5,
    subsample=0.8,
    colsample_bytree=0.8,
    n_jobs=-1,
    random_state=42
)
model.fit(X_train, y_train)

# 5. é¢„æµ‹
print("Predicting 2025...")
y_pred = model.predict(X_test)

test_df['yhat'] = y_pred.astype(int)
test_df['diff'] = test_df['yhat'] - test_df['y']
test_df['error_pct'] = (test_df['diff'].abs() / test_df['y']) * 100

overall_mape = test_df['error_pct'].mean()

# 6. ç”Ÿæˆåˆ†ææŠ¥å‘Š
lines = []
lines.append("="*60)
lines.append(f"ğŸ›¡ï¸ 2025 FULL YEAR BACKTEST REPORT")
lines.append(f"Overall MAPE: {overall_mape:.2f}%")
lines.append("="*60)

# æœˆåº¦è¯¯å·®åˆ†æ
lines.append("\n[Monthly Performance]")
lines.append(f"{'Month':<10} | {'MAPE':<10} | {'Bad Days (>10%)'}")
lines.append("-" * 50)

monthly_stats = test_df.groupby('month')['error_pct'].agg(['mean', lambda x: (x>10).sum()])
monthly_stats.columns = ['MAPE', 'Bad_Days']

for m, row in monthly_stats.iterrows():
    lines.append(f"{m:<10} | {row['MAPE']:>6.2f}%   | {row['Bad_Days']}")

# æ‰¾å‡ºè¯¯å·®æœ€å¤§çš„ Top 5 æ—¥å­
lines.append("\n[Top 5 Worst Predictions]")
worst_days = test_df.sort_values('error_pct', ascending=False).head(5)
for _, row in worst_days.iterrows():
    d_str = row['ds'].strftime('%Y-%m-%d')
    lines.append(f"{d_str}: Actual={int(row['y']):,}, Pred={int(row['yhat']):,}, Err={row['error_pct']:.2f}%")

# ä¿å­˜æŠ¥å‘Š
with open("backtest_2025_report.txt", "w", encoding="utf-8") as f:
    f.write("\n".join(lines))

print(f"Backtest Complete. Overall MAPE: {overall_mape:.2f}%")
print("See backtest_2025_report.txt for details.")
